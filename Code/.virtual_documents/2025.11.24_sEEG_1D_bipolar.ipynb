


from numpy import pi, linspace, sin, cos, arctan2, degrees, diff, arange, c_, array, asarray, delete, argmax, around
from numpy import zeros, zeros_like, ones, correlate, std, exp, log, corrcoef,fill_diagonal, gradient, unravel_index, insert
from numpy import sort, concatenate, angle, unwrap, mod, arctan2, degrees, sqrt, digitize, roll, percentile, insert, cumsum

from numpy.random import default_rng, randint
from numpy.linalg import eigh, norm

from scipy.fft    import fft, fftfreq, rfft, rfftfreq
from scipy.signal import find_peaks, hilbert
from scipy.stats  import entropy

from matplotlib.pyplot import subplots

from pandas  import read_csv

from sklearn.preprocessing import StandardScaler

import json






sz = 0

sr = 1000      # samples per second

patient_load = "HS_2018wuzhisen"

folder = '/Users/geroldbaier/Library/CloudStorage/Dropbox/EEG/EEG_Data/' + patient_load + '/'

path = folder + 'Series/WZS_Seizure_' + str(sz+1) + '.csv'

data_raw = read_csv(path, delimiter=r"\s+")
data_raw = data_raw.values

rows, chans = data_raw.shape

time = linspace(0, rows//sr, rows)

labels_chars =  folder + 'Series/WZS_Labels.txt'

all_labels_list = []

with open(labels_chars, 'r') as file:
        
    for line in file:

        label = line[:-1]
        all_labels_list.append(label)

label_dict_chars = folder + 'Series/All_onsets_label_dict.txt'

with open(label_dict_chars, "r") as dict_file:

    labels_dict_read = json.load(dict_file)


folder = '/Users/geroldbaier/Library/CloudStorage/Dropbox/EEG/EEG_Data/' + patient_load + '/'

onset_chars = folder + 'onset_reduced.txt'

onset_times = read_csv(onset_chars, header=None)

onset_time = onset_times[0][sz]

patient = 'HS_2018WZS' # HS_2018WZS, Tumor_2017LZJ, FCD_2019ZPY

if patient == 'HS_2018WZS':

    faulty_channel = (10, 44, 45)

    data_raw = delete(data_raw, faulty_channel, axis=1)

    chans -= len(faulty_channel)

    all_labels_list = delete(all_labels_list, faulty_channel)        

data_raw.shape, len(all_labels_list), float(onset_time)






def data_filter(data, sr, low, high):
    """
    Default filtering of multiple time series. 
    Low : cut-off for high-pass
    High: cut-off for low-pass (Maximum is Nyquist frequency, sr / 2)

    data: nxm numpy array. Rows are time points, columns are channels
    sr: sampling rate   
    
    return: filtered data
    """
    from scipy.signal import butter, sosfiltfilt

    order = 5

    filter_settings = [low, high, order]

    sos = butter(order, (low, high), btype='bandpass', fs=sr, output='sos')

    data_filt = sosfiltfilt(sos, data, padlen=200, axis=0)

        
    return data_filt

def data_filter_stop(data, sr, low, high):
    """
    Default filtering of multiple time series. 
    Low : cut-off for low-pass
    High: cut-off for high-pass (Maximum is Nyquist frequency, sr / 2)

    data: nxm numpy array. Rows are time points, columns are channels
    sr: sampling rate   
    
    return: filtered data
    """
    from scipy.signal import butter, sosfiltfilt

    order = 5

    filter_settings = [low, high, order]

    sos = butter(order, (low, high), btype='bandstop', fs=sr, output='sos')

    data_filt = sosfiltfilt(sos, data, padlen=100, axis=0)

        
    return data_filt

def calculate_kl_mi(phase_angles, amp_values, n_bins=18):
    """
    Calculates the Kullback-Leibler Modulation Index (KL-MI) for Phase-Amplitude Coupling.
    
    Parameters:
    phase_angles (array): Phase angles in radians.
    amp_values (array): Corresponding amplitude values.
    n_bins (int): Number of phase bins to use.
    
    Returns:
    mi (float): The KL Modulation Index value.
    p_obs (array): The observed probability distribution (normalized amplitude per bin).
    p_uniform (array): The uniform distribution for comparison.
    """
    
    # 1. Define phase bins (from -pi to pi)
    phase_bins = linspace(-pi, pi, n_bins + 1)
    bin_indices = digitize(phase_angles, bins=phase_bins) - 1
    
    # 2. Calculate the *sum* of amplitudes in each bin, not the mean.  "amplitude histogram".
    sum_amp_by_bin = zeros(n_bins)
    for bin_idx in range(n_bins):
        sum_amp_by_bin[bin_idx] = amp_values[bin_indices == bin_idx].sum()
        
    # 3. Normalize the summed amplitudes to create a probability distribution.
    p_obs = sum_amp_by_bin / sum_amp_by_bin.sum()
    
    # 4. Uniform (null) distribution.
    p_uniform = ones(n_bins) / n_bins
    
    # 5. Kullback-Leibler Divergence
    # KL(P_obs || P_uniform) = sum(P_obs * log(P_obs / P_uniform))
    # Entropy(pk, qk) = sum(pk * log(pk / qk))
    kl_div = entropy(p_obs, p_uniform)
    
    # 6. Normalize KL to Modulation Index.
    mi = kl_div / log(n_bins)
    
    return mi, kl_div, p_obs, p_uniform

def data_band_pass_filter_2d(data_2d, cut_low, cut_high, order, sr):


    from scipy.signal import butter, sosfiltfilt
    from numpy import arange, zeros, asarray

    sos = butter(order, (cut_low, cut_high), btype='bandpass', fs=sr, output='sos')

    data_filtered = sosfiltfilt(sos, data_2d, padlen=100, axis=0)
        
    return data_filtered

def phase_lock(data):
    
    rows, chans   = data.shape
    signal_phases = zeros((rows, chans))

    for index, column in enumerate(data.T):

        instantaneous_phase = angle(hilbert(column))
        inst_phase_unwrap   = unwrap(instantaneous_phase)
        signal_phases[:, index] = inst_phase_unwrap
    
    phase_lock = zeros((chans, chans))

    for index1, column in enumerate(signal_phases.transpose()):
        for index2 in arange(index1+1, chans):
              
            phase_diff = column - signal_phases[:, index2]
            phase_lock[index1, index2] = abs(sum(exp(-1j*phase_diff)))/phase_diff.size

    phase_lock = phase_lock + phase_lock.T

    return phase_lock





order = 5

freqs_band = (0.5, 20)

data_band = data_band_pass_filter_2d(data_raw, freqs_band[0], freqs_band[1], order, sr)

data_band.shape


n_features = 10

win_downsample = 1

win_1, win_2 = 0, 145000

window_length  = 10000

electrode = 'X'

feature_names = all_labels_list[labels_dict_read[electrode][0]:labels_dict_read[electrode][0]+n_features]

chan_start, chan_stop = labels_dict_read[electrode][0], labels_dict_read[electrode][1]
chans = chan_stop - chan_start


voltages_pre = data_band[win_1:win_1+window_length:win_downsample,chan_start:chan_start+n_features]


voltages_ict = data_band[win_2:win_2+window_length:win_downsample,chan_start:chan_start+n_features]



fig, ax = subplots(ncols=2, figsize=(7, 2))

ax[0].imshow(voltages_pre.T, aspect='auto', cmap='bwr');
ax[1].imshow(voltages_ict.T, aspect='auto', cmap='bwr');











# freq_bands = ((0.001, 0.5), (0.5, 20), (20, 100))

# # Embedding
# dims = 2

# # Filter order
# order = 5

# data_VdV = zeros((data_raw.shape[0], data_raw.shape[1], dims, len(freq_bands)))
# data     = zeros((data_raw.shape[0], data_raw.shape[1], dims, len(freq_bands)))

# # onset_time = all_data[patient][0][0][sz]

# fig1, ax1 = subplots(nrows=len(freq_bands))
# fig2, ax2 = subplots(nrows=len(freq_bands))
# # fig3, ax3 = subplots(nrows=len(freq_bands))
# # fig4, ax4 = subplots(nrows=len(freq_bands))

# for index, band in enumerate(freq_bands):

#     data_band = data_band_pass_filter_2d(data_raw, freq_bands[index][0], freq_bands[index][1], order, sr)
    
#     data_band         = asarray(data_band)
#     data_band_grad    = gradient(data_band, axis=0)
#     # data_band_grad2   = gradient(data_band_grad, axis=0)

#     # std_skl   = StandardScaler()

#     # data_band_normed       = std_skl.fit_transform(data_band)
#     # data_band_grad_normed  = std_skl.fit_transform(data_band_grad)
#     # data_band_grad2_normed = std_skl.fit_transform(data_band_grad2)
    
#     data_VdV[:,:,0,index] = data_band
#     data_VdV[:,:,1,index] = data_band_grad
#     # data_VdV[:,:,2,index] = data_band_grad2_normed

#     # for chan in arange(chans):

#     #     chan_angls = arctan2(*data_VdV[:, chan, :, index].T)

#     #     data[:,chan,0,index] = norm(data_VdV[:, chan, :, index], axis=1)

#     #     aangle               = arctan2(*data_VdV[:, chan, :, index].T)
#     #     aangle_unwrap        = unwrap(aangle)
#     #     aangle_line          = linspace(0, aangle_unwrap[-1] - aangle_unwrap[0], aangle_unwrap.size)
#     #     data[:,chan,1,index] = aangle


#     ax1[index].imshow(data_VdV[:, :,0,index].T, aspect='auto', cmap='bwr');
#     # ax3[index].imshow(data    [:, :,0,index].T, aspect='auto', cmap='bwr', vmin=0,  vmax=5);

#     if index == 0:
#         ax2[index].imshow(data_VdV[:,:,1,index].T, aspect='auto', cmap='bwr');
#         # ax4[index].imshow(data    [:,:,1,index].T, aspect='auto', cmap='twilight_shifted');

#     elif index == 1:
#         ax2[index].imshow(data_VdV[:,:,1,index].T, aspect='auto', cmap='bwr');
#         # ax4[index].imshow(data    [:,:,1,index].T, aspect='auto', cmap='twilight_shifted');

#     title_chars = 'Voltage Freq band ' + str(freq_bands[index][0]) + ' - ' + str(freq_bands[index][1])
#     ax1[index].set_title(title_chars)
#     title_chars = 'V-Gradient Freq band ' + str(freq_bands[index][0]) + ' - ' + str(freq_bands[index][1])
#     ax2[index].set_title(title_chars)
#     # title_chars = 'Radii Freq band ' + str(freq_bands[index][0]) + ' - ' + str(freq_bands[index][1])
#     # ax3[index].set_title(title_chars)
#     # title_chars = 'Phases Freq band ' + str(freq_bands[index][0]) + ' - ' + str(freq_bands[index][1])
#     # ax4[index].set_title(title_chars)

#     # ax1[index].vlines(onset_time*sr, 0, chans-1, color="k", linewidth=1)
#     # ax2[index].vlines(onset_time*sr, 0, chans-1, color="k", linewidth=1)
#     # ax3[index].vlines(onset_time*sr, 0, chans-1, color="k", linewidth=1)
#     # ax4[index].vlines(onset_time*sr, 0, chans-1, color="k", linewidth=1)


# fig1.tight_layout()
# fig2.tight_layout()
# # fig3.tight_layout()
# # fig4.tight_layout()

# print(data.shape)
# print('Rows, Chans, Embedding, Band')


# win_downsample = 1

# win_1, win_2 = 20000, 160000

# window_length  = 10000 # 2000 for 0.5-13, 30000 for <0.5

# dim = 0

# freq_band = 1

# window_pre = data_VdV[win_1:win_1+window_length:win_downsample,:, dim, freq_band]
# window_ict = data_VdV[win_2:win_2+window_length:win_downsample,:, dim, freq_band]

# fig, ax = subplots(nrows=2, figsize=(5, 5))

# ax[0].imshow(window_pre.T, aspect='auto', cmap='bwr', origin='lower');
# ax[0].set_xticklabels([])

# ax[1].imshow(window_ict.T, aspect='auto', cmap='bwr', origin='lower');
# ax[1].set_xticklabels([])

# fig.tight_layout()

# window_pre.shape








# EEG data

n_features = 10

win_downsample = 5

win_1, win_2 = 0, 145000

window_length  = 10000

dim = 0
freq_band = 1

electrode = 'X'

feature_names = all_labels_list[labels_dict_read[electrode][0]:labels_dict_read[electrode][0]+n_features]

chan_start, chan_stop = labels_dict_read[electrode][0], labels_dict_read[electrode][1]
chans = chan_stop - chan_start


voltages_pre = data_band[win_1:win_1+window_length:win_downsample,chan_start:chan_start+n_features]


voltages_ict = data_band[win_2:win_2+window_length:win_downsample,chan_start:chan_start+n_features]


charges_pre = cumsum(voltages_pre, axis=1)
charges_ict = cumsum(voltages_ict, axis=1)



fig, ax = subplots(ncols=2, nrows=2, figsize=(5, 5))

# Plot comparison
ax[0, 0].imshow(charges_pre[:, 1:].T, aspect='auto', cmap='bwr')
ax[1, 0].imshow(charges_ict[:, 1:].T, aspect='auto', cmap='bwr')

ax[0, 1].imshow(voltages_pre.T, aspect='auto', cmap='bwr')
ax[1, 1].imshow(voltages_ict.T, aspect='auto', cmap='bwr')

# ax[0].hlines(0, 0, reconstructed_2d.shape[1], color='k')
# ax.legend()
ax[0, 0].set_xlabel('Time')
ax[0, 0].set_ylabel('Channel')
ax[0, 0].set_title('Net charge preictal')

ax[1, 0].set_xlabel('Time')
ax[1, 0].set_ylabel('Channel')
ax[1, 0].set_title('Net charge ictal')

ax[0, 1].set_xlabel('Time')
ax[0, 1].set_ylabel('Channel')
ax[0, 1].set_title('Voltage preictal')

ax[1, 1].set_xlabel('Time')
ax[1, 1].set_ylabel('Channel')
ax[1, 1].set_title('Voltage ictal')

# titlechars = 'Band ' + str(freq_bands) + ' Hz'

# fig.suptitle(titlechars)

fig.tight_layout()

# titlechars


voltages_pre.shape, charges_pre.shape


voltages_pre[10, :]


charges_pre[10, :]


diff(charges_pre[10, :])








import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
from scipy.stats import shapiro, normaltest
import pandas as pd

def binary_normality_check(data, feature_names=None, alpha=0.05):
    """
    Simple binary check: Gaussian vs Non-Gaussian
    Returns clear yes/no for each feature
    """
    if feature_names is None:
        feature_names = [f'Feature_{i}' for i in range(data.shape[1])]
    
    results = []
    
    for feature_idx, feature_name in enumerate(feature_names):
        feature_data = data[:, feature_idx]
        feature_data = feature_data[~np.isnan(feature_data)]
        
        # Two simple normality tests
        shapiro_stat, shapiro_p = shapiro(feature_data)
        dagostino_stat, dagostino_p = normaltest(feature_data)
        
        # Binary decision: if BOTH tests say normal -> Gaussian, else Non-Gaussian
        is_gaussian = (shapiro_p > alpha) and (dagostino_p > alpha)
        
        # Simple visualization
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))
        
        # Histogram with normal curve
        n, bins, patches = ax1.hist(feature_data, bins=30, density=True, alpha=0.7, color='lightblue')
        xmin, xmax = ax1.get_xlim()
        x = np.linspace(xmin, xmax, 100)
        p = stats.norm.pdf(x, np.mean(feature_data), np.std(feature_data))
        ax1.plot(x, p, 'r-', linewidth=2)
        ax1.set_title(f'{feature_name}\nGaussian: {is_gaussian}')
        ax1.grid(True, alpha=0.3)
        
        # Q-Q plot
        stats.probplot(feature_data, dist="norm", plot=ax2)
        ax2.set_title(f'Q-Q Plot\nShapiro p: {shapiro_p:.4f}')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Store simple results
        results.append({
            'Feature': feature_name,
            'Is_Gaussian': is_gaussian,
            'Shapiro_p': shapiro_p,
            'Dagostino_p': dagostino_p,
            'Verdict': 'GAUSSIAN' if is_gaussian else 'NON-GAUSSIAN'
        })
        
        print(f"{feature_name}: {('GAUSSIAN' if is_gaussian else 'NON-GAUSSIAN')}")
        print(f"  Shapiro p-value: {shapiro_p:.4f} {'✓' if shapiro_p > alpha else '✗'}")
        print(f"  Dagostino p-value: {dagostino_p:.4f} {'✓' if dagostino_p > alpha else '✗'}")
        print("-" * 40)
    
    return pd.DataFrame(results)

# Generate sample data
np.random.seed(42)
n_samples = 200

# Mix of Gaussian and non-Gaussian
data = np.column_stack([
    np.random.normal(0, 1, n_samples),      # Gaussian
    np.random.exponential(2, n_samples),    # Non-Gaussian
    np.random.lognormal(0, 1, n_samples),   # Non-Gaussian  
    np.random.normal(5, 2, n_samples),      # Gaussian
    np.random.uniform(-2, 2, n_samples),    # Non-Gaussian
    np.random.chisquare(2, n_samples)       # Non-Gaussian
])

feature_names = ['Normal_1', 'Exponential', 'LogNormal', 'Normal_2', 'Uniform', 'ChiSquared']

# Run the simple check
results = binary_normality_check(data, feature_names)

print("\nFINAL SUMMARY:")
print("=" * 50)
for _, row in results.iterrows():
    status = "✓ GAUSSIAN" if row['Is_Gaussian'] else "✗ NON-GAUSSIAN"
    print(f"{row['Feature']:15} -> {status}")





import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
from scipy.stats import shapiro, normaltest
import pandas as pd

def binary_normality_check(data, feature_names=None, alpha=0.05):
    """
    Simple binary check: Gaussian vs Non-Gaussian
    Returns clear yes/no for each feature
    """
    if feature_names is None:
        feature_names = [f'Feature_{i}' for i in range(data.shape[1])]
    
    results = []
    
    for feature_idx, feature_name in enumerate(feature_names):
        feature_data = data[:, feature_idx]
        feature_data = feature_data[~np.isnan(feature_data)]
        
        # Two simple normality tests
        shapiro_stat, shapiro_p = shapiro(feature_data)
        dagostino_stat, dagostino_p = normaltest(feature_data)
        
        # Binary decision: if BOTH tests say normal -> Gaussian, else Non-Gaussian
        is_gaussian = (shapiro_p > alpha) and (dagostino_p > alpha)
        
        # Simple visualization
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))
        
        # Histogram with normal curve
        n, bins, patches = ax1.hist(feature_data, bins=50, density=True, alpha=0.7, color='lightblue')
        xmin, xmax = ax1.get_xlim()
        x = np.linspace(xmin, xmax, 100)
        p = stats.norm.pdf(x, np.mean(feature_data), np.std(feature_data))
        ax1.plot(x, p, 'r-', linewidth=2)
        ax1.set_title(f'{feature_name}\nGaussian: {is_gaussian}')
        ax1.grid(True, alpha=0.3)
        
        # Q-Q plot
        stats.probplot(feature_data, dist="norm", plot=ax2)
        ax2.set_title(f'Q-Q Plot\nShapiro p: {shapiro_p:.4f}')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Store simple results
        results.append({
            'Feature': feature_name,
            'Is_Gaussian': is_gaussian,
            'Shapiro_p': shapiro_p,
            'Dagostino_p': dagostino_p,
            'Verdict': 'GAUSSIAN' if is_gaussian else 'NON-GAUSSIAN'
        })
        
        print(f"{feature_name}: {('GAUSSIAN' if is_gaussian else 'NON-GAUSSIAN')}")
        print(f"  Shapiro p-value: {shapiro_p:.4f} {'✓' if shapiro_p > alpha else '✗'}")
        print(f"  Dagostino p-value: {dagostino_p:.4f} {'✓' if dagostino_p > alpha else '✗'}")
        print("-" * 40)
    
    return pd.DataFrame(results)


# EEG data

n_features = 6

win_downsample = 20

win_1 = 0

window_length  = 100000

dim = 0
freq_band = 1

electrode = 'X'

# feature_names = all_labels_list[labels_dict_read[electrode][0]:labels_dict_read[electrode][0]+n_features]

# chan_start, chan_stop = labels_dict_read[electrode][0], labels_dict_read[electrode][1]
# chans = chan_stop - chan_start


data = data_band[win_1:win_1+window_length:win_downsample,chan_start:chan_start+n_features]

# Check
results = binary_normality_check(data, feature_names)

print("\nFINAL SUMMARY:")
print("=" * 50)
for _, row in results.iterrows():
    status = "✓ GAUSSIAN" if row['Is_Gaussian'] else "✗ NON-GAUSSIAN"
    print(f"{row['Feature']:15} -> {status}")


for index, label in enumerate(all_labels_list):

    if label[0] == electrode:

        print(label)


















win_downsample = 1

win_1, win_2 = 100000, 200000

dim = 0

window_lengths = (20000, 2000, 200)

for index in arange(len(freq_bands)):

    window_pre = data_VdV[win_1:win_1+window_lengths[index]:win_downsample,:, dim, index]
    window_ict = data_VdV[win_2:win_2+window_lengths[index]:win_downsample,:, dim, index]

    fig, ax = subplots(ncols=2, nrows=2, figsize=(5, 5))

    gradients_pre = window_pre.copy()
    gradients_ict = window_ict.copy()
    
    reconstruct_pre = cumsum(gradients_pre, axis=1)
    reconstruct_ict = cumsum(gradients_ict, axis=1)
    
    # Plot comparison
    ax[0, 0].imshow(reconstruct_pre.T, aspect='auto', cmap='bwr')
    ax[1, 0].imshow(reconstruct_ict.T, aspect='auto', cmap='bwr')
    
    ax[0, 1].imshow(window_pre.T, aspect='auto', cmap='bwr')
    ax[1, 1].imshow(window_ict.T, aspect='auto', cmap='bwr')
    
    # ax[0].hlines(0, 0, reconstructed_2d.shape[1], color='k')
    # ax.legend()
    ax[0, 0].set_xlabel('Time')
    ax[0, 0].set_ylabel('Channel')
    ax[0, 0].set_title('Net charge preictal')
    
    ax[1, 0].set_xlabel('Time')
    ax[1, 0].set_ylabel('Channel')
    ax[1, 0].set_title('Net charge ictal')
    
    ax[0, 1].set_xlabel('Time')
    ax[0, 1].set_ylabel('Channel')
    ax[0, 1].set_title('Voltage preictal')
    
    ax[1, 1].set_xlabel('Time')
    ax[1, 1].set_ylabel('Channel')
    ax[1, 1].set_title('Voltage ictal')
    
    titlechars = 'Band' + str(freq_bands[index]) + ' Hz'
    fig.suptitle(titlechars)
    fig.tight_layout()





















labels_dict_read


dict_min = labels_dict_read['A'][1] - labels_dict_read['A'][0]

for key in labels_dict_read:
    
    elec_diff = labels_dict_read[key][1] - labels_dict_read[key][0]

    if elec_diff < dict_min:

        dict_min = elec_diff

dict_min


dict_min = 7

data_VdV_2D = zeros((data_VdV.shape[0], dict_min, len(labels_dict_read)))

for index, key in enumerate(labels_dict_read):

    print(data_VdV[:, labels_dict_read[key][0]:labels_dict_read[key][0]+dict_min, dim, freq_band].shape)
    data_VdV_2D[:, :, index] = data_VdV[:, labels_dict_read[key][0]:labels_dict_read[key][0]+dict_min, dim, freq_band]

data_VdV_2D.shape


inital_value = 0

slic = 5000

gradients_2d = data_VdV_2D[slic, :, :].copy()
reconstructed_2d = cumsum(gradients_2d, axis=1)

fig, ax = subplots(nrows=3, figsize=(4, 10))

# Plot comparison
ax[0].imshow(reconstructed_2d.T, aspect='auto', cmap='Reds', interpolation='Gaussian')
ax[1].plot(reconstructed_2d+abs(reconstructed_2d.min()), label='True Profile', linewidth=2, c='r')
ax[2].plot(gradients_2d.T, label='True Profile', linewidth=2, c='r')


# ax[0].hlines(0, 0, reconstructed_2d.shape[1], color='k')
# ax.legend()
ax[0].set_xlabel('Position')
ax[0].set_ylabel('Contact')
ax[0].set_title('Reconstructed Net charge')

ax[1].set_xlabel('Position')
ax[1].set_ylabel('Concentration')
ax[1].set_title('Net Charge')

ax[2].set_xlabel('Position')
ax[2].set_ylabel('Voltage')
ax[2].set_title('Gradients')

fig.tight_layout()





from numpy import zeros_like

net_chard_2D = zeros_like(data_VdV_2D)

scics = data_VdV_2D.shape[0]

for slic in arange(scics):
    
    gradients_2d = data_VdV_2D[slic, :, :].copy()
    net_chard_2D[slic, :, :] = cumsum(gradients_2d, axis=0)

net_chard_2D.shape


data_VdV_2D[slic, :, :].shape


time_steps = 1000

win_start = 210000

downsample = 5

win_volt = data_VdV_2D[win_start:win_start+time_steps:downsample, :, 0]
win_conc = net_chard_2D[win_start:win_start+time_steps:downsample, :, 0]

fig, ax = subplots()

ax.plot(win_volt);

fig, ax = subplots()

ax.plot(win_conc + abs(win_conc.min()));









from numpy.random import rand
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import HTML


rows, cols = data_VdV_2D.shape[1:]

# time_steps = 2000
# win_start = 220500

downsample = 5

data_3d = net_chard_2D[win_start:win_start+time_steps:downsample, :, :].copy()

vmin = 0
vmax = 0.8*data_3d.max()

fig, ax = plt.subplots(figsize=(8, 7))
plt.close()

# Heatmap
im = ax.imshow(data_3d[0], cmap='Reds', aspect='auto', interpolation='Gaussian', vmin=vmin, vmax=vmax)
ax.set_title(f'Votages, Time step: 0')
plt.colorbar(im, ax=ax, shrink=0.5)

def update(frame):
    im.set_array(data_3d[frame])
    ax.set_title(f'Time step: {frame}')
    return [im]

# Animation
anim = FuncAnimation(
    fig, 
    update, 
    frames=len(data_3d),
    interval=100,  # msecs between frames
    blit=True
)

# Display
HTML(anim.to_jshtml())

















import plotly.graph_objects as go
import numpy as np

# Create data
x = np.linspace(-3, 3, 25)
y = np.linspace(-3, 3, 25)
X, Y = np.meshgrid(x, y)

time_steps = 20
data_3d = np.zeros((time_steps, len(y), len(x)))

for t in range(time_steps):
    data_3d[t] = np.sin(X + t * 0.3) * np.cos(Y - t * 0.2)

# Create frames for animation
frames = []
for t in range(time_steps):
    frames.append(go.Frame(
        data=[go.Surface(z=data_3d[t], x=x, y=y, colorscale='Viridis', showscale=False)],  # No colorbar
        name=f'frame{t}'
    ))

# Create initial figure - WITHOUT colorbar
fig = go.Figure(
    data=[go.Surface(z=data_3d[0], x=x, y=y, colorscale='Viridis', showscale=False)],
    frames=frames
)

# Compact layout
fig.update_layout(
    title='3D Surface Animation',
    width=700,   # Reduced width since no colorbar needed
    height=600,
    scene=dict(
        zaxis=dict(range=[np.min(data_3d), np.max(data_3d)]),
        aspectmode='cube',
        camera=dict(eye=dict(x=1.8, y=1.8, z=1.2))  # Better view angle
    ),
    updatemenus=[dict(
        type="buttons",
        buttons=[dict(label="▶ Play",
                     method="animate",
                     args=[None, {"frame": {"duration": 100, "redraw": True},
                                 "fromcurrent": True}])],
        x=0.05,
        xanchor='left',
        y=0.02,
        yanchor='bottom'
    )]
)

fig.show()


import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import HTML
from mpl_toolkits.mplot3d import Axes3D

# Generate data
x = np.linspace(-2, 2, 25)
y = np.linspace(-2, 2, 25)
X, Y = np.meshgrid(x, y)

time_steps = 20
data_3d = np.zeros((time_steps, len(y), len(x)))
for t in range(time_steps):
    data_3d[t] = np.sin(X**2 + Y**2 + t * 0.2)

# Create 3D figure
fig = plt.figure(figsize=(10, 6))  # Smaller figure
ax = fig.add_subplot(111, projection='3d')

z_min, z_max = np.min(data_3d), np.max(data_3d)
surface = [ax.plot_surface(X, Y, data_3d[0], cmap='viridis', 
                          vmin=z_min, vmax=z_max)]

ax.set_zlim(z_min, z_max)
ax.set_title('Time step: 0')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.view_init(30, 30)

fig.colorbar(surface[0], ax=ax, shrink=0.5, aspect=20)

def update(frame):
    for surf in surface:
        surf.remove()
    surface.clear()
    
    new_surface = ax.plot_surface(X, Y, data_3d[frame], cmap='viridis',
                                 vmin=z_min, vmax=z_max)
    surface.append(new_surface)
    ax.set_title(f'Time step: {frame}')
    return surface

# Create animation with minimal controls
anim = FuncAnimation(fig, update, frames=len(data_3d), interval=150, blit=False)

# Convert to HTML without the step labels
html_output = anim.to_jshtml()
html_output = html_output.replace("'frame_{frame}'", "''")  # Remove frame labels

HTML(html_output)








# time_steps = 2000
# rows, cols = data_VdV_2D.shape[1:]

# Create sample data - you would replace this with your array
data_3d = data_VdV_2D[win_start:win_start+time_steps:downsample, :, :].copy()

vmin = data_3d.min()
vmax = data_3d.max()

# Create the figure and axis
fig, ax = plt.subplots(figsize=(5, 4))
plt.close()  # Prevents static display

# Initialize the heatmap
im = ax.imshow(data_3d[0], cmap='bwr', aspect='auto', interpolation='Gaussian', vmin=vmin, vmax=vmax)
ax.set_title(f'Votages, Time step: 0')
plt.colorbar(im, ax=ax, shrink=0.5)

# Animation update function
def update(frame):
    im.set_array(data_3d[frame])
    ax.set_title(f'Time step: {frame}')
    return [im]

# Create animation
anim = FuncAnimation(
    fig, 
    update, 
    frames=len(data_3d),
    interval=100,  # milliseconds between frames
    blit=True
)

# Display in JupyterLab
HTML(anim.to_jshtml())


fig, ax = subplots()

win_start = 220500

ax.plot(data_VdV_2D[win_start:win_start+time_steps:downsample, :, 0]);

fig, ax = subplots()

win_start = 220500

ax.plot(net_chard_2D[win_start:win_start+time_steps:downsample, :, 0]);




















from numpy import flip

data_VdV.shape, flip(window_pre, axis=0).shape


# dVdt


win_downsample = 1

win_1, win_2 = 101200, 221300

window_length  = 300

dim = 0

freq_band = 2

window_pre = data[win_1:win_1+window_length:win_downsample,:,dim,freq_band]

full_matrix_time_pre = phase_lock(window_pre.T)


window_ict = data[win_2:win_2+window_length:win_downsample,:,dim,freq_band]

full_matrix_time_ict = phase_lock(window_ict.T)


fig, ax = subplots(nrows=3, ncols=2, figsize=(6, 8))

ax[0, 0].imshow(full_matrix_time_pre, aspect='auto', vmin=0.6, vmax=1, origin='lower', cmap='bwr');

title_chars = 'start ' + str(win_1/sr) + ' secs'
ax[0, 0].set_title(title_chars)
ax[0, 1].imshow(full_matrix_time_ict, aspect='auto', vmin=0.6, vmax=1, origin='lower', cmap='bwr');
title_chars = 'start ' + str(win_2/sr) + ' secs'
ax[0, 1].set_title(title_chars)
ax[0, 1].set_yticklabels([])
ax[1, 0].bar(arange(full_matrix_time_pre.shape[0]), full_matrix_time_pre.sum(axis=0))
ax[1, 1].bar(arange(full_matrix_time_ict.shape[0]), full_matrix_time_ict.sum(axis=0))

_, y_max1 = ax[1, 0].get_ylim()
_, y_max2 = ax[1, 1].get_ylim()

ax[1, 0].set_ylim(0, 1.1*max(y_max1, y_max2))
ax[1, 1].set_ylim(0, 1.1*max(y_max1, y_max2))

ax[1, 0].margins(x=0)
ax[1, 1].margins(x=0)

ax[2, 0].imshow(window_pre.T, aspect='auto', cmap='twilight_shifted', vmin=0, vmax=6.2)
ax[2, 1].imshow(window_ict.T, aspect='auto', cmap='twilight_shifted', vmin=0, vmax=6.2)

fig.tight_layout()



# Voltages


win_downsample = 2

win_1, win_2 = 131000, 134000

window_length  = 1200

dim = 0

freq_band = 1

window_pre = data[win_1:win_1+window_length:win_downsample,:,dim,freq_band]

full_matrix_time_pre = phase_lock(window_pre.T)


window_ict = data[win_2:win_2+window_length:win_downsample,:,dim,freq_band]

full_matrix_time_ict = phase_lock(window_ict.T)


fig, ax = subplots(nrows=3, ncols=2, figsize=(5, 7))

ax[0, 0].imshow(full_matrix_time_pre, aspect='auto', vmin=0.55, vmax=0.95, origin='lower', cmap='bwr');

title_chars = 'start ' + str(win_1//sr) + ' secs'
ax[0, 0].set_title(title_chars)
ax[0, 1].imshow(full_matrix_time_ict, aspect='auto', vmin=0.55, vmax=0.95, origin='lower', cmap='bwr');
title_chars = 'start ' + str(win_2//sr) + ' secs'
ax[0, 1].set_title(title_chars)
ax[0, 1].set_yticklabels([])
ax[1, 0].bar(arange(full_matrix_time_pre.shape[0]), full_matrix_time_pre.sum(axis=0))
ax[1, 1].bar(arange(full_matrix_time_ict.shape[0]), full_matrix_time_ict.sum(axis=0))

_, y_max1 = ax[1, 0].get_ylim()
_, y_max2 = ax[1, 1].get_ylim()

ax[1, 0].set_ylim(0, 1.1*max(y_max1, y_max2))
ax[1, 1].set_ylim(0, 1.1*max(y_max1, y_max2))

ax[1, 0].margins(x=0)
ax[1, 1].margins(x=0)

ax[2, 0].imshow(window_pre.T, aspect='auto', cmap='twilight_shifted', vmin=0, vmax=6.2)
ax[2, 1].imshow(window_ict.T, aspect='auto', cmap='twilight_shifted', vmin=0, vmax=6.2)

fig.tight_layout()



























band_flag = 'ISA'
# band_flag = 'ISA'

division = 0.1

if band_flag == 'ISA':

    low, high = 0.001, division

elif band_flag == 'STD':

    low, high = division, 5

data = data_filter(data_raw, sr, low, high)

rows, chans = data.shape

stretching_factor = 500

fig, ax = subplots(figsize=(7.5, 4))

ax.plot(time[120000:], data[120000:, :] - stretching_factor*arange(chans));
# ax.vlines(onset_time, 0, -35000)
ax.set_yticklabels([])
# ax.set_yticks(-arange(chans)*stretching_factor);
# ax.set_yticklabels(arange(chans));

fig, ax = subplots(figsize=(7, 3))

ax.imshow(data[120000:, :].T, aspect='auto', cmap='bwr', vmin=-150, vmax=150);

fig_folder = '/Users/geroldbaier/Library/CloudStorage/Dropbox/EEG/Patterns_ISA/MS_Figures/' + patient

title_chars = fig_folder + '/01_Sz' + str(sz+1) + '_' + band_flag +  '_EEG_All.png'

# fig.savefig(title_chars, format='png', transparent=True, dpi=300)

title_chars, data.shape


fig, ax = subplots(figsize=(7, 5))

ax.imshow(data[200000:260000, :].T, aspect='auto', cmap='bwr', vmin=-150, vmax=150);

data.shape

fig_folder = '/Users/geroldbaier/Library/CloudStorage/Dropbox/EEG/Patterns_ISA/MS_Figures/' + patient

title_chars = fig_folder + '/01_Sz' + str(sz+1) + '_' + band_flag +  '_EEG_All.png'

# fig.savefig(title_chars, format='png', transparent=True, dpi=300)

title_chars, data.shape


fig, ax = subplots(figsize=(7, 5))

ax.imshow(data[230000:260000, :].T, aspect='auto', cmap='bwr', vmin=-150, vmax=150);

data.shape

fig_folder = '/Users/geroldbaier/Library/CloudStorage/Dropbox/EEG/Patterns_ISA/MS_Figures/' + patient

title_chars = fig_folder + '/01_Sz' + str(sz+1) + '_' + band_flag +  '_EEG_All.png'

# fig.savefig(title_chars, format='png', transparent=True, dpi=300)

title_chars, data.shape





data_raw.shape


start_sample = 100000

window_size = 12000

chan = 21

filter_settings = ((0.1, 0.5), (8, 13))

shift = 1000

shifts = 150

max_number_allowed = (data_raw.shape[0] - start_sample - window_size) // shift

if shifts > max_number_allowed:

    shifts = max_number_allowed

    print('Maximal number of shifts is:', max_number_allowed)
    print('')

start_time = (start_sample + window_size/2)/sr
stop_time  = start_time + shifts*shift/sr

kl_values = list()
mi_values = list()


for index in arange(shifts):

    start, stop = start_sample + shift*index, start_sample + shift*index + window_size
    
    data_slow = data_filter(data_raw[start:stop, chan], sr, filter_settings[0][0], filter_settings[0][1])
    data_fast = data_filter(data_raw[start:stop, chan], sr, filter_settings[1][0], filter_settings[1][1])
    
    data_slow_norm = (data_slow - data_slow.mean()) / data_slow.std()
    data_slow_grad_norm = (gradient(data_slow, axis=0) - gradient(data_slow, axis=0).mean()) / gradient(data_slow, axis=0).std()
    
    angle_radians = arctan2(data_slow_grad_norm, data_slow_norm)  # order: y, x
    angle_degrees = degrees(angle_radians)
    
    
    # 1. Find all peaks and troughs (inverts signal to find troughs as peaks)
    peak_indices, _   = find_peaks( data_fast)
    trough_indices, _ = find_peaks(-data_fast) # Find troughs as peaks of the inverted signal
    
    # 2. Combine and sort all extrema indices. We need to pair consecutive min and max.
    all_extrema_indices = sort(concatenate((peak_indices, trough_indices)))
    
    # 3. We'll create arrays to store our calculated amplitudes and their time points
    amplitudes      = []
    amplitude_times = []
    
    # 4. Iterate through the sequence of extrema to find min-max or max-min pairs
    for i in range(1, len(all_extrema_indices)):
        prev_idx = all_extrema_indices[i-1]
        curr_idx = all_extrema_indices[i]
        
        # Check if previous and current extrema are of different types (one min, one max)
        # We do this by checking if one is in peak_indices and the other is not.
        if (prev_idx in peak_indices) != (curr_idx in peak_indices):
            amp_val = abs((data_fast[prev_idx] - data_fast[curr_idx]) / 2.0)
            # Assign time to the midpoint between the two extrema
            mid_time = (time[prev_idx] + time[curr_idx]) / 2.0
            
            amplitudes.append(amp_val)
            amplitude_times.append(mid_time)
    
    # # 5. Interpolate this discrete amplitude vector back to original length.
    from scipy.interpolate import interp1d
    
    if len(amplitude_times) > 3: # Ensure we have enough points to interpolate
        amplitude_interpolator = interp1d(amplitude_times, amplitudes, kind='linear', bounds_error=False, fill_value="extrapolate")
        peak_based_envelope = amplitude_interpolator(time[:stop-start])
    else:
        peak_based_envelope = zeros_like(time[:stop-start])
    
    
    phase_angles = angle_radians.copy()
    amp_values   = peak_based_envelope.copy()
    
    # Calculate the MI and get the distributions
    modulation_index, kl_div, p_observed, p_uniform = calculate_kl_mi(phase_angles, amp_values, n_bins=18)
    
    kl_values.append(kl_div)
    mi_values.append(modulation_index)


fig, ax = subplots(figsize=(6, 3))

# ax.bar(arange(shifts), kl_values, label=str(chan)+' KL', color='b');
ax.bar(arange(shifts), mi_values, label='Chan ' + str(chan), color='g');
no_ticks = 3
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI')
ax.legend();











start_sample = 80000

# window_size = 6000
window_size = 12000

# filter_settings = ((1, 5), (6, 20))
filter_settings = ((0.1, 1), (13, 30))

shift = 500

shifts = 80

samples, chans = data_raw.shape

max_number_allowed = (data_raw.shape[0] - start_sample - window_size) // shift

if shifts > max_number_allowed:

    shifts = max_number_allowed

    print('Maximal number of shifts is:', max_number_allowed)
    print('')

start_time = (start_sample + window_size/2)/sr
stop_time  = start_time + shifts*shift/sr

kl_values_all = list()
mi_values_all = list()


for chan in arange(chans):

    kl_values = list()
    mi_values = list()
    
    for index in arange(shifts):
    
        start, stop = start_sample + shift*index, start_sample + shift*index + window_size
        
        data_slow = data_filter(data_raw[start:stop, chan], sr, filter_settings[0][0], filter_settings[0][1])
        data_fast = data_filter(data_raw[start:stop, chan], sr, filter_settings[1][0], filter_settings[1][1])
        
        data_slow_norm = (data_slow - data_slow.mean()) / data_slow.std()
        data_slow_grad_norm = (gradient(data_slow, axis=0) - gradient(data_slow, axis=0).mean()) / gradient(data_slow, axis=0).std()
        
        angle_radians = arctan2(data_slow_grad_norm, data_slow_norm)  # order: y, x
        angle_degrees = degrees(angle_radians)
        
        
        # 1. Find all peaks and troughs (inverts signal to find troughs as peaks)
        peak_indices, _   = find_peaks( data_fast)
        trough_indices, _ = find_peaks(-data_fast) # Find troughs as peaks of the inverted signal
        
        # 2. Combine and sort all extrema indices. We need to pair consecutive min and max.
        all_extrema_indices = sort(concatenate((peak_indices, trough_indices)))
        
        # 3. We'll create arrays to store our calculated amplitudes and their time points
        amplitudes      = []
        amplitude_times = []
        
        # 4. Iterate through the sequence of extrema to find min-max or max-min pairs
        for i in range(1, len(all_extrema_indices)):
            prev_idx = all_extrema_indices[i-1]
            curr_idx = all_extrema_indices[i]
            
            # Check if previous and current extrema are of different types (one min, one max)
            # We do this by checking if one is in peak_indices and the other is not.
            if (prev_idx in peak_indices) != (curr_idx in peak_indices):
                amp_val = abs((data_fast[prev_idx] - data_fast[curr_idx]) / 2.0)
                # Assign time to the midpoint between the two extrema
                mid_time = (time[prev_idx] + time[curr_idx]) / 2.0
                
                amplitudes.append(amp_val)
                amplitude_times.append(mid_time)
        
        # # 5. Interpolate this discrete amplitude vector back to original length.
        from scipy.interpolate import interp1d
        
        if len(amplitude_times) > 3: # Ensure we have enough points to interpolate
            amplitude_interpolator = interp1d(amplitude_times, amplitudes, kind='linear', bounds_error=False, fill_value="extrapolate")
            peak_based_envelope = amplitude_interpolator(time[:stop-start])
        else:
            peak_based_envelope = zeros_like(time[:stop-start])
        
        
        phase_angles = angle_radians.copy()
        amp_values   = peak_based_envelope.copy()
        
        # Calculate the MI and get the distributions
        modulation_index, kl_div, p_observed, p_uniform = calculate_kl_mi(phase_angles, amp_values, n_bins=18)
        
        kl_values.append(kl_div)
        mi_values.append(modulation_index)

    kl_values_all.append(kl_values)
    mi_values_all.append(mi_values)


kl_values_all = asarray(kl_values_all)
mi_values_all = asarray(mi_values_all)

best_chan, _ = unravel_index(argmax(mi_values_all), mi_values_all.shape)

mi_max = mi_values_all.max()

mi_values_all.shape, best_chan, mi_max, filter_settings


fig, ax = subplots(figsize=(6, 4))

no_ticks = 5

im = ax.imshow(mi_values_all[:26, :],aspect='auto', cmap='Reds');
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI channels')
fig.colorbar(im, shrink=0.5);


fig, ax = subplots(figsize=(5, 3))

im = ax.plot(mi_values_all[10, :]);
im = ax.plot(mi_values_all[11, :]);
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_ylim(0, 0.2);



start, stop = 80000, 116000

chan_start, chan_stop = 10, 12

low, high = 0.1, 1

data_slow = data_filter(data_raw[start:stop, chan_start:chan_stop], sr, low, high)

rectified_signal_slow = abs(data_slow)

rectified_signal_enve = data_filter(rectified_signal_slow, sr, 0.1, 4)

low, high = 13, 30

data_fast = data_filter(data_raw[start:stop, chan_start:chan_stop], sr, low, high)


fig, ax = subplots(figsize=(8, 4))

chan = 0

ax.plot(time[start:stop], data_slow[:, chan]);
ax.plot(time[start:stop], data_fast[:, chan]+500);

fig.suptitle('Fast & Slow');

data_slow.shape


# Assume 'filtered_signal' is your band-pass filtered data [3,4] Hz
# Assume 'time' is the corresponding time vector

# 1. Find all peaks and troughs (inverts signal to find troughs as peaks)
peak_indices, _   = find_peaks( data_fast[:,chan])
trough_indices, _ = find_peaks(-data_fast[:,chan]) # Find troughs as peaks of the inverted signal

# 2. Combine and sort all extrema indices. We need to pair consecutive min and max.
all_extrema_indices = sort(concatenate((peak_indices, trough_indices)))

# 3. We'll create arrays to store our calculated amplitudes and their time points
amplitudes      = []
amplitude_times = []

# 4. Iterate through the sequence of extrema to find min-max or max-min pairs
for i in range(1, len(all_extrema_indices)):
    prev_idx = all_extrema_indices[i-1]
    curr_idx = all_extrema_indices[i]
    
    # Check if previous and current extrema are of different types (one min, one max)
    # We do this by checking if one is in peak_indices and the other is not.
    if (prev_idx in peak_indices) != (curr_idx in peak_indices):
        amp_val = abs((data_fast[prev_idx, chan] - data_fast[curr_idx, chan]) / 2.0)
        # Assign time to the midpoint between the two extrema
        mid_time = (time[prev_idx] + time[curr_idx]) / 2.0
        
        amplitudes.append(amp_val)
        amplitude_times.append(mid_time)

# Now 'amplitudes' and 'amplitude_times' are discrete vectors you can analyze.

# # 5. (Optional) To compare with the Hilbert envelope, you can interpolate this
# # discrete amplitude vector back to your original time grid.
from scipy.interpolate import interp1d

if len(amplitude_times) > 3: # Ensure we have enough points to interpolate
    amplitude_interpolator = interp1d(amplitude_times, amplitudes, kind='linear', bounds_error=False, fill_value="extrapolate")
    peak_based_envelope = amplitude_interpolator(time[:stop-start])
else:
    peak_based_envelope = zeros_like(time[:stop-start])


fig, ax = subplots(figsize=(8, 4))

# ax.plot(time[:stop-start], data_fast[:, 0], label='Fast Signal', alpha=0.7)
ax.plot(time[:stop-start], 0.4*data_slow[:, 0], label='Slow Signal', alpha=0.7)
#plt.plot(time, np.abs(signal.hilbert(filtered_signal)), label='Hilbert Envelope', alpha=0.7)
# ax.plot(amplitude_times, amplitudes, 'ro', label='Peak-to-Trough Amplitude Points')
ax.plot(time[:stop-start], peak_based_envelope, 'g-', label='Peak-based Envelope (Interpolated)')
ax.legend()
ax.hlines(0, 0, (stop-start)/sr, color='k')

# fig, ax = subplots()

data_slow_norm = (data_slow[:, chan] - data_slow[:, chan].mean()) / data_slow[:, chan].std()
data_slow_grad_norm = (gradient(data_slow[:, chan], axis=0) - gradient(data_slow[:, chan], axis=0).mean()) / gradient(data_slow[:, chan], axis=0).std()

angle_radians = arctan2(data_slow_grad_norm, data_slow_norm)  # order: y, x
angle_degrees = degrees(angle_radians)

# fig, ax = subplots(figsize=(4, 2))

# ax.scatter(angle_degrees, peak_based_envelope, c='b', s=5);

# vector_lengths = sqrt((peak_based_envelope*sin(angle_degrees))**2 + (peak_based_envelope*cos(angle_degrees))**2)

# fig, ax = subplots(figsize=(4, 2))

# ax.hist(vector_lengths, bins=50)

# fig, ax = subplots(figsize=(4, 2))

# ax.plot(peak_based_envelope*sin(angle_degrees), peak_based_envelope*cos(angle_degrees), 'rd');

# vector_lengths.size, angle_degrees.size



phase_angles = angle_radians.copy()
amp_values   = peak_based_envelope.copy()

# 1. Define your phase bins
n_bins = 18  # A common choice. 18 bins = 20° per bin.
phase_bins = linspace(-pi, pi, n_bins + 1) # Creates edges from -π to π

# 2. Digitize: Assign each phase angle to a bin index
bin_indices = digitize(phase_angles, bins=phase_bins) - 1
# np.digitize returns values from 1 to n_bins. Subtract 1 to get indices from 0 to n_bins-1.

# 3. Calculate the mean amplitude for each bin
mean_amp_by_bin = zeros(n_bins)
for bin_idx in range(n_bins):
    # Find all amplitude values where the phase falls into the current bin
    amps_in_bin = amp_values[bin_indices == bin_idx]
    # Calculate the mean amplitude for this bin
    if len(amps_in_bin) > 0:
        mean_amp_by_bin[bin_idx] = amps_in_bin.mean()
    else:
        mean_amp_by_bin[bin_idx] = 0 # or np.nan

# 4. (Optional) Calculate the center of each bin for plotting
bin_centers = (phase_bins[:-1] + phase_bins[1:]) / 2

n_surrogates = 100 # Typically 200-1000

surrogate_means = zeros((n_surrogates, n_bins))

# Create surrogate datasets by breaking the phase-amplitude relationship
for i in range(n_surrogates):
    # The key: randomly shift the amplitude time series
    # This preserves the distribution of amplitudes and phases separately,
    # but randomizes their relationship to each other.
    shifted_amp_values = roll(amp_values, randint(len(amp_values)))
    
    # Now calculate the mean amplitude for each bin using the
    # ORIGINAL phases but the SHIFTED amplitudes
    surrogate_means_per_bin = zeros(n_bins)
    for bin_idx in range(n_bins):
        amps_in_bin = shifted_amp_values[bin_indices == bin_idx]
        if len(amps_in_bin) > 0:
            surrogate_means_per_bin[bin_idx] = amps_in_bin.mean()
        else:
            surrogate_means_per_bin[bin_idx] = 0
    surrogate_means[i, :] = surrogate_means_per_bin

# Calculate the 95th percentile of the surrogate distribution for each bin
upper_ci = percentile(surrogate_means, 95, axis=0)
lower_ci = percentile(surrogate_means, 5, axis=0)

# Now plot the observed data with the confidence interval
fig, ax = subplots(figsize=(8, 4))

ax.bar(bin_centers, mean_amp_by_bin, width=2*pi/n_bins, alpha=0.7, edgecolor='k', label='Observed')
ax.fill_between(bin_centers, lower_ci, upper_ci, color='gray', alpha=0.5, label='95% Surrogate CI')
ax.set_title("PAC Distribution with Significance Testing")
ax.set_xlabel("Phase Angle (radians)")
ax.set_ylabel("Mean Amplitude")
ax.set_xticks([-pi, -pi/2, 0, pi/2, pi],
           [r'$-\pi$', r'$-\pi/2$', '0', r'$\pi/2$', r'$\pi$'])
ax.legend()
ax.grid(alpha=0.3)

title_chars = 'PAC_2018WZS_Sz' + str(sz+1) + '_channel_21.png'

# fig.savefig(title_chars, format='png', transparent=False, dpi=300)

title_chars



# Calculate the MI and get the distributions
modulation_index, kl_div, p_observed, p_uniform = calculate_kl_mi(phase_angles, amp_values, n_bins=18)

print(f"KL Divergence from uniform: {kl_div:.3f}")
print(f"Modulation Index (MI): {modulation_index:.3f}")



# Plot the observed distribution vs. the uniform distribution
bin_centers = (linspace(-pi, pi, 19)[:-1] + (pi/18)) # Calculate bin centers for 18 bins

fig, ax = subplots(figsize=(8, 4))

width = (2 * pi) / 18 * 0.8 # Width of the bars

ax.bar(bin_centers, p_observed, width=width, alpha=0.7, label='Observed (P_obs)', color='blue')
ax.axhline(1/18, color='red', linestyle='--', linewidth=2, label='Uniform (P_uniform)')
ax.set_title(f'Amplitude Distribution by Phase Bin (MI = {modulation_index:.3f})')
ax.set_xlabel('Phase Angle (radians)')
ax.set_ylabel('Probability')
ax.set_xticks([-pi, -pi/2, 0, pi/2, pi],
           [r'$-\pi$', r'$-\pi/2$', '0', r'$\pi/2$', r'$\pi$'])
ax.legend()
ax.grid(alpha=0.3)









chan_select = 21

start_sample = 200000

window_size = 10000

# filter_settings = ((1, 5), (6, 20))
filter_settings = ((0.1, 1), (4, 8))

shift = 500

shifts = 145

samples, chans = data_raw.shape

max_number_allowed = (data_raw.shape[0] - start_sample - window_size) // shift

if shifts > max_number_allowed:

    shifts = max_number_allowed

    print('Maximal number of shifts:', max_number_allowed)
    print('')

start_time = (start_sample + window_size/2)/sr
stop_time  = start_time + shifts*shift/sr

# kl_values_all = list()
mi_values_all = list()


# for chan in [chan for chan in arange(chans) if chan != chan_select ]:
for chan in arange(chans):

    # kl_values = list()
    mi_values = list()
    
    for index in arange(shifts):
    
        start, stop = start_sample + shift*index, start_sample + shift*index + window_size
        
        data_slow = data_filter(data_raw[start:stop, chan_select], sr, filter_settings[0][0], filter_settings[0][1])
        data_fast = data_filter(data_raw[start:stop, chan], sr, filter_settings[1][0], filter_settings[1][1])
        
        data_slow_norm = (data_slow - data_slow.mean()) / data_slow.std()
        data_slow_grad_norm = (gradient(data_slow, axis=0) - gradient(data_slow, axis=0).mean()) / gradient(data_slow, axis=0).std()
        
        angle_radians = arctan2(data_slow_grad_norm, data_slow_norm)  # order: y, x
        angle_degrees = degrees(angle_radians)
        
        
        # 1. Find all peaks and troughs (inverts signal to find troughs as peaks)
        peak_indices, _   = find_peaks( data_fast)
        trough_indices, _ = find_peaks(-data_fast) # Find troughs as peaks of the inverted signal
        
        # 2. Combine and sort all extrema indices. We need to pair consecutive min and max.
        all_extrema_indices = sort(concatenate((peak_indices, trough_indices)))
        
        # 3. We'll create arrays to store our calculated amplitudes and their time points
        amplitudes      = []
        amplitude_times = []
        
        # 4. Iterate through the sequence of extrema to find min-max or max-min pairs
        for i in range(1, len(all_extrema_indices)):
            prev_idx = all_extrema_indices[i-1]
            curr_idx = all_extrema_indices[i]
            
            # Check if previous and current extrema are of different types (one min, one max)
            # We do this by checking if one is in peak_indices and the other is not.
            if (prev_idx in peak_indices) != (curr_idx in peak_indices):
                amp_val = abs((data_fast[prev_idx] - data_fast[curr_idx]) / 2.0)
                # Assign time to the midpoint between the two extrema
                mid_time = (time[prev_idx] + time[curr_idx]) / 2.0
                
                amplitudes.append(amp_val)
                amplitude_times.append(mid_time)
        
        # # 5. Interpolate this discrete amplitude vector back to original length.
        from scipy.interpolate import interp1d
        
        if len(amplitude_times) > 3: # Ensure we have enough points to interpolate
            amplitude_interpolator = interp1d(amplitude_times, amplitudes, kind='linear', bounds_error=False, fill_value="extrapolate")
            peak_based_envelope = amplitude_interpolator(time[:stop-start])
        else:
            peak_based_envelope = zeros_like(time[:stop-start])
        
        
        phase_angles = angle_radians.copy()
        amp_values   = peak_based_envelope.copy()
        
        # Calculate the MI and get the distributions
        modulation_index, _, p_observed, p_uniform = calculate_kl_mi(phase_angles, amp_values, n_bins=18)
        
        # kl_values.append(kl_div)
        mi_values.append(modulation_index)

    # kl_values_all.append(kl_values)
    mi_values_all.append(mi_values)


# kl_values_all = asarray(kl_values_all)
mi_values_all = asarray(mi_values_all)

# kl_values_full = insert(kl_values_all, chan_select, zeros(kl_values_all.shape[1]), axis=0)
# mi_values_full = insert(mi_values_all, chan_select, zeros(mi_values_all.shape[1]), axis=0)

mi_max = mi_values_all.max()

best_chan, best_win = unravel_index(argmax(mi_values_all), mi_values_all.shape)

mi_values_all.shape, best_chan, mi_max, filter_settings


fig, ax = subplots(figsize=(6, 3))

im = ax.imshow(mi_values_all, cmap='Reds');

no_ticks = 5
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI channels')
fig.colorbar(im, shrink=0.5);


# these are matplotlib.patch.Patch properties
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)

# place a text box in upper left in axes coords
textstr = 'Slow Chan: ' + str(chan_select)
ax.text(1.05, 0.97, textstr, transform=ax.transAxes, fontsize=8,
    verticalalignment='top', bbox=props);


fig, ax = subplots(figsize=(6, 3))

im = ax.imshow(mi_values_all, cmap='Reds');

no_ticks = 5
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI channels')
fig.colorbar(im, shrink=0.5);


# these are matplotlib.patch.Patch properties
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)

# place a text box in upper left in axes coords
textstr = 'Slow Chan: ' + str(chan_select)
ax.text(1.05, 0.97, textstr, transform=ax.transAxes, fontsize=8,
    verticalalignment='top', bbox=props);








fig, ax = subplots(figsize=(6, 3))

im = ax.imshow(mi_values_all, cmap='Reds');

no_ticks = 5
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI channels')
fig.colorbar(im, shrink=0.5);


# these are matplotlib.patch.Patch properties
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)

# place a text box in upper left in axes coords
textstr = 'Slow Chan: ' + str(chan_select)
ax.text(1.05, 0.97, textstr, transform=ax.transAxes, fontsize=8,
    verticalalignment='top', bbox=props);


fig, ax = subplots(figsize=(6, 3))

im = ax.imshow(mi_values_all, cmap='Reds');

no_ticks = 5
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI channels')
fig.colorbar(im, shrink=0.5);


# these are matplotlib.patch.Patch properties
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)

# place a text box in upper left in axes coords
textstr = 'Slow Chan: ' + str(chan_select)
ax.text(1.05, 0.97, textstr, transform=ax.transAxes, fontsize=8,
    verticalalignment='top', bbox=props);


fig, ax = subplots(figsize=(6, 3))

im = ax.imshow(mi_values_all, cmap='Reds');

no_ticks = 5
ax.set_xticks(linspace(0, shifts, no_ticks))
ax.set_xticklabels(linspace(start_time, stop_time, no_ticks))
ax.set_xlabel('Time (secs)')
ax.set_ylabel('MI channels')
fig.colorbar(im, shrink=0.5);


# these are matplotlib.patch.Patch properties
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)

# place a text box in upper left in axes coords
textstr = 'Slow Chan: ' + str(chan_select)
ax.text(1.05, 0.97, textstr, transform=ax.transAxes, fontsize=8,
    verticalalignment='top', bbox=props);











start, stop = 190000, 220000

chan_start, chan_stop = 0, 35

low, high = 0.5, 4

data_slow = data_filter(data_raw[start:stop, chan_start:chan_stop], sr, low, high)

rectified_signal_slow = abs(data_slow)

rectified_signal_enve = data_filter(rectified_signal_slow, sr, 0.1, 4)

low, high = 13, 20

data_fast = data_filter(data_raw[start:stop, chan_start:chan_stop], sr, low, high)

data_slow.shape


fig, ax = subplots(figsize=(8, 4))

chan = 0

ax.plot(time[start:stop], 1*data_slow[:, chan_select]);
ax.plot(time[start:stop], 3*data_fast[:, 10]+200);

fig.suptitle('Fast & Slow');


rows = data_slow.shape[0]
# frequencies
freqs = rfftfreq(rows, 1 / sr)

# amplitude
amplitude_s = (2.0 / rows)*abs(rfft(data_slow[:,chan]))
amplitude_f = (2.0 / rows)*abs(rfft(data_fast[:,chan]))

fig, ax = subplots()

ax.plot(freqs, amplitude_s);
ax.plot(freqs, amplitude_f);
ax.set_xlim(0, 25);
ax.set_xlabel('Frequency (Hz)')
ax.set_ylabel('Amplitude');


# Assume 'filtered_signal' is your band-pass filtered data [3,4] Hz
# Assume 'time' is the corresponding time vector

# 1. Find all peaks and troughs (inverts signal to find troughs as peaks)
peak_indices, _   = find_peaks( data_fast[:,chan])
trough_indices, _ = find_peaks(-data_fast[:,chan]) # Find troughs as peaks of the inverted signal

# 2. Combine and sort all extrema indices. We need to pair consecutive min and max.
all_extrema_indices = sort(concatenate((peak_indices, trough_indices)))

# 3. We'll create arrays to store our calculated amplitudes and their time points
amplitudes      = []
amplitude_times = []

# 4. Iterate through the sequence of extrema to find min-max or max-min pairs
for i in range(1, len(all_extrema_indices)):
    prev_idx = all_extrema_indices[i-1]
    curr_idx = all_extrema_indices[i]
    
    # Check if previous and current extrema are of different types (one min, one max)
    # We do this by checking if one is in peak_indices and the other is not.
    if (prev_idx in peak_indices) != (curr_idx in peak_indices):
        amp_val = abs((data_fast[prev_idx, chan] - data_fast[curr_idx, chan]) / 2.0)
        # Assign time to the midpoint between the two extrema
        mid_time = (time[prev_idx] + time[curr_idx]) / 2.0
        
        amplitudes.append(amp_val)
        amplitude_times.append(mid_time)

# Now 'amplitudes' and 'amplitude_times' are discrete vectors you can analyze.

# # 5. (Optional) To compare with the Hilbert envelope, you can interpolate this
# # discrete amplitude vector back to your original time grid.
from scipy.interpolate import interp1d

if len(amplitude_times) > 3: # Ensure we have enough points to interpolate
    amplitude_interpolator = interp1d(amplitude_times, amplitudes, kind='linear', bounds_error=False, fill_value="extrapolate")
    peak_based_envelope = amplitude_interpolator(time[:stop-start])
else:
    peak_based_envelope = zeros_like(time[:stop-start])


fig, ax = subplots(figsize=(8, 4))

# ax.plot(time[:stop-start], data_fast[:, 0], label='Fast Signal', alpha=0.7)
ax.plot(time[:stop-start], 0.4*data_slow[:, 0], label='Slow Signal', alpha=0.7)
#plt.plot(time, np.abs(signal.hilbert(filtered_signal)), label='Hilbert Envelope', alpha=0.7)
# ax.plot(amplitude_times, amplitudes, 'ro', label='Peak-to-Trough Amplitude Points')
ax.plot(time[:stop-start], peak_based_envelope, 'g-', label='Peak-based Envelope (Interpolated)')
ax.legend()
ax.hlines(0, 0, (stop-start)/sr, color='k')

peak_based_envelope.size


# fig, ax = subplots()

data_slow_norm = (data_slow[:, chan] - data_slow[:, chan].mean()) / data_slow[:, chan].std()
data_slow_grad_norm = (gradient(data_slow[:, chan], axis=0) - gradient(data_slow[:, chan], axis=0).mean()) / gradient(data_slow[:, chan], axis=0).std()

angle_radians = arctan2(data_slow_grad_norm, data_slow_norm)  # order: y, x
angle_degrees = degrees(angle_radians)

fig, ax = subplots(figsize=(4, 2))

ax.scatter(angle_degrees, peak_based_envelope, c='b', s=5);

vector_lengths = sqrt((peak_based_envelope*sin(angle_degrees))**2 + (peak_based_envelope*cos(angle_degrees))**2)

fig, ax = subplots(figsize=(4, 2))

ax.hist(vector_lengths, bins=50)

fig, ax = subplots(figsize=(4, 2))

ax.plot(peak_based_envelope*sin(angle_degrees), peak_based_envelope*cos(angle_degrees), 'rd');

vector_lengths.size, angle_degrees.size






# Assume you have these two arrays already:
# phase_angles: The phase of the slow rhythm (in radians, from -π to π or 0 to 2π) for each amplitude estimate.
# amp_values: The corresponding amplitude values of the fast rhythm.

phase_angles = angle_radians.copy()
amp_values   = peak_based_envelope.copy()

# 1. Define your phase bins
n_bins = 18  # A common choice. 18 bins = 20° per bin.
phase_bins = linspace(-pi, pi, n_bins + 1) # Creates edges from -π to π

# 2. Digitize: Assign each phase angle to a bin index
bin_indices = digitize(phase_angles, bins=phase_bins) - 1
# np.digitize returns values from 1 to n_bins. Subtract 1 to get indices from 0 to n_bins-1.

# 3. Calculate the mean amplitude for each bin
mean_amp_by_bin = zeros(n_bins)
for bin_idx in range(n_bins):
    # Find all amplitude values where the phase falls into the current bin
    amps_in_bin = amp_values[bin_indices == bin_idx]
    # Calculate the mean amplitude for this bin
    if len(amps_in_bin) > 0:
        mean_amp_by_bin[bin_idx] = amps_in_bin.mean()
    else:
        mean_amp_by_bin[bin_idx] = 0 # or np.nan

# 4. (Optional) Calculate the center of each bin for plotting
bin_centers = (phase_bins[:-1] + phase_bins[1:]) / 2

# 5. Plot the distribution
fig, ax = subplots(figsize=(8, 4))

ax.bar(bin_centers, mean_amp_by_bin, width=2*pi/n_bins, alpha=0.7, edgecolor='k')
ax.set_title("Distribution of Amplitude by Phase")
ax.set_xlabel("Phase Angle (radians)")
ax.set_ylabel("Mean Amplitude")
ax.set_xticks([-pi, -pi/2, 0, pi/2, pi],
           [r'$-\pi$', r'$-\pi/2$', '0', r'$\pi/2$', r'$\pi$'])
ax.grid(alpha=0.5)







n_surrogates = 100 # Typically 200-1000
surrogate_means = zeros((n_surrogates, n_bins))

# Create surrogate datasets by breaking the phase-amplitude relationship
for i in range(n_surrogates):
    # The key: randomly shift the amplitude time series
    # This preserves the distribution of amplitudes and phases separately,
    # but randomizes their relationship to each other.
    shifted_amp_values = roll(amp_values, randint(len(amp_values)))
    
    # Now calculate the mean amplitude for each bin using the
    # ORIGINAL phases but the SHIFTED amplitudes
    surrogate_means_per_bin = zeros(n_bins)
    for bin_idx in range(n_bins):
        amps_in_bin = shifted_amp_values[bin_indices == bin_idx]
        if len(amps_in_bin) > 0:
            surrogate_means_per_bin[bin_idx] = amps_in_bin.mean()
        else:
            surrogate_means_per_bin[bin_idx] = 0
    surrogate_means[i, :] = surrogate_means_per_bin

# Calculate the 95th percentile of the surrogate distribution for each bin
upper_ci = percentile(surrogate_means, 95, axis=0)
lower_ci = percentile(surrogate_means, 5, axis=0)

# Now plot the observed data with the confidence interval
fig, ax = subplots(figsize=(8, 4))

ax.bar(bin_centers, mean_amp_by_bin, width=2*pi/n_bins, alpha=0.7, edgecolor='k', label='Observed')
ax.fill_between(bin_centers, lower_ci, upper_ci, color='gray', alpha=0.5, label='95% Surrogate CI')
ax.set_title("PAC Distribution with Significance Testing")
ax.set_xlabel("Phase Angle (radians)")
ax.set_ylabel("Mean Amplitude")
ax.set_xticks([-pi, -pi/2, 0, pi/2, pi],
           [r'$-\pi$', r'$-\pi/2$', '0', r'$\pi/2$', r'$\pi$'])
ax.legend()
ax.grid(alpha=0.3)

title_chars = 'PAC_2018WZS_Sz' + str(sz+1) + '_channel_21.png'

# fig.savefig(title_chars, format='png', transparent=False, dpi=300)

title_chars



fig_folder





# Calculate the MI and get the distributions
modulation_index, kl_div, p_observed, p_uniform = calculate_kl_mi(phase_angles, amp_values, n_bins=18)

print(f"KL Divergence from uniform: {kl_div:.3f}")
print(f"Modulation Index (MI): {modulation_index:.3f}")



# Plot the observed distribution vs. the uniform distribution
bin_centers = (linspace(-pi, pi, 19)[:-1] + (pi/18)) # Calculate bin centers for 18 bins

fig, ax = subplots(figsize=(8, 4))

width = (2 * pi) / 18 * 0.8 # Width of the bars

ax.bar(bin_centers, p_observed, width=width, alpha=0.7, label='Observed (P_obs)', color='blue')
ax.axhline(1/18, color='red', linestyle='--', linewidth=2, label='Uniform (P_uniform)')
ax.set_title(f'Amplitude Distribution by Phase Bin (MI = {modulation_index:.3f})')
ax.set_xlabel('Phase Angle (radians)')
ax.set_ylabel('Probability')
ax.set_xticks([-pi, -pi/2, 0, pi/2, pi],
           [r'$-\pi$', r'$-\pi/2$', '0', r'$\pi/2$', r'$\pi$'])
ax.legend()
ax.grid(alpha=0.3)






fig, ax = subplots(figsize=(4, 4))

ax.scatter(phase_angles, amp_values, alpha=0.1, s=2) # s=size, alpha=transparency
ax.set_xlabel('Phase Angle (rad)')
ax.set_ylabel('Amplitude')
ax.set_title('Raw Phase-Amplitude Data Points')
ax.set_xlim(-pi, pi);







